{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f83686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   I     P_sist     P_dist       qPA       Pulse  BreathFreq    Gravity  Class\n",
      "0  1  13.592433  12.220855  8.416754   75.921057   21.635259  40.000000      2\n",
      "1  2  15.775386  13.586879  8.725890   63.813564   19.718734  41.530427      2\n",
      "2  3   3.649369   1.904802  0.000000  197.210213   19.045471  52.730745      3\n",
      "3  4  17.264362  13.700638  8.733333  143.636181   17.621141  34.679911      2\n",
      "4  5  12.705183   9.485389  1.747626   82.636672   12.209535  69.375882      3\n",
      "Temperature Max, Min post normalization: 1.72, -1.23\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "print(df.head())\n",
    "df = df.drop('I', axis=1)\n",
    "\n",
    "# 1. Diferença de Pressões\n",
    "df['P_diff'] = df['P_sist'] - df['P_dist']\n",
    "\n",
    "# 2. Razão de Pressão para Frequência Cardíaca\n",
    "df['Pressure_per_Pulse'] = df['P_sist'] / df['Pulse']\n",
    "\n",
    "# 3. Índice Respiratório\n",
    "df['Resp_Index'] = df['qPA'] / df['BreathFreq']\n",
    "\n",
    "## Removing our target variable\n",
    "\n",
    "selected_features = [\"qPA\", \"Pulse\", \"BreathFreq\" ,\"P_diff\", \"Pressure_per_Pulse\", \"Resp_Index\"]\n",
    "X = df[selected_features].values\n",
    "y_gravity = df[\"Gravity\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(X_scaled[0]):0.2f}, {np.min(X_scaled[0]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0e572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      P_sist     P_dist       qPA       Pulse  BreathFreq    Gravity  \\\n",
      "0  13.592433  12.220855  8.416754   75.921057   21.635259  40.000000   \n",
      "1  15.775386  13.586879  8.725890   63.813564   19.718734  41.530427   \n",
      "2   3.649369   1.904802  0.000000  197.210213   19.045471  52.730745   \n",
      "3  17.264362  13.700638  8.733333  143.636181   17.621141  34.679911   \n",
      "4  12.705183   9.485389  1.747626   82.636672   12.209535  69.375882   \n",
      "\n",
      "     P_diff  Pressure_per_Pulse  Resp_Index  class_1  class_2  class_3  \\\n",
      "0  1.371578            0.179034    0.389030    False     True    False   \n",
      "1  2.188507            0.247211    0.442518    False     True    False   \n",
      "2  1.744567            0.018505    0.000000    False    False     True   \n",
      "3  3.563724            0.120195    0.495617    False     True    False   \n",
      "4  3.219794            0.153748    0.143136    False    False     True   \n",
      "\n",
      "   class_4  \n",
      "0    False  \n",
      "1    False  \n",
      "2    False  \n",
      "3    False  \n",
      "4    False  \n"
     ]
    }
   ],
   "source": [
    "cat_variables = ['Class']\n",
    "\n",
    "# This will replace the columns with the one-hot encoded ones and keep the columns outside 'columns' argument as it is.\n",
    "df = pd.get_dummies(data = df,\n",
    "                         prefix = \"class\",\n",
    "                         columns = cat_variables)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f04abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 1050\n",
      "test samples: 450\n"
     ]
    }
   ],
   "source": [
    "# Define X (features), y_class e y_gravity\n",
    "y_class = df[[\"class_1\", \"class_2\", \"class_3\", \"class_4\"]].values\n",
    "\n",
    "# Divide em treino e teste\n",
    "X_train, X_test, y_train, y_test, y_class_train, y_class_test = train_test_split(X_scaled, y_gravity, y_class, train_size = 0.7, random_state = RANDOM_STATE)\n",
    "\n",
    "print(f'train samples: {len(X_train)}\\ntest samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d937b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 6) (1050, 4)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_class_train.shape)\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb15ab8",
   "metadata": {},
   "source": [
    "usando K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e0d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE across folds: 2.0863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_scaled):\n",
    "    X_train_cv, X_val_cv = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_cv, y_val_cv = y_gravity[train_idx], y_gravity[val_idx]\n",
    "    \n",
    "    # Build a new model for each fold\n",
    "    model_cv = tf.keras.Sequential([\n",
    "        tf.keras.Input(X_train_cv.shape[1]),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model_cv.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    model_cv.fit(X_train_cv, y_train_cv, epochs=800, verbose=0)\n",
    "    \n",
    "    # Evaluate on validation fold\n",
    "    loss, mae = model_cv.evaluate(X_val_cv, y_val_cv, verbose=0)\n",
    "    cv_scores.append(mae)\n",
    "\n",
    "print(f\"Mean MAE across folds: {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1d226",
   "metadata": {},
   "source": [
    "Usando K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c1db601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Fold classifier accuracy: 88.67%\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Fold classifier accuracy: 91.00%\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Fold classifier accuracy: 92.00%\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Fold classifier accuracy: 93.67%\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Fold classifier accuracy: 90.00%\n",
      "Mean classifier accuracy across folds: 91.07%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "clf_cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_scaled):\n",
    "    X_train_cv, X_val_cv = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_cv, y_val_cv = y_gravity[train_idx], y_gravity[val_idx]\n",
    "    y_class_train_cv, y_class_val_cv = y_class[train_idx], y_class[val_idx]\n",
    "\n",
    "    # 1. Train regression model\n",
    "    model_cv = tf.keras.Sequential([\n",
    "        tf.keras.Input(X_train_cv.shape[1]),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model_cv.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    model_cv.fit(X_train_cv, y_train_cv, epochs=800, verbose=0)\n",
    "\n",
    "    # 2. Predict gravity for train and validation sets\n",
    "    y_train_pred_cv = model_cv.predict(X_train_cv)\n",
    "    y_val_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    # 3. Train classifier on regression predictions (train set)\n",
    "    clf_model_cv = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    clf_model_cv.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    clf_model_cv.fit(y_train_pred_cv, y_class_train_cv, epochs=800, verbose=0)\n",
    "\n",
    "    # 4. Evaluate classifier on validation set\n",
    "    val_acc = clf_model_cv.evaluate(y_val_pred_cv, y_class_val_cv, verbose=0)[1]\n",
    "    print(f\"Fold classifier accuracy: {val_acc*100:.2f}%\")\n",
    "    clf_cv_scores.append(val_acc)\n",
    "\n",
    "print(f\"Mean classifier accuracy across folds: {np.mean(clf_cv_scores)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77bb86ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fold accuracy:\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "Regression accuracy (within ±5.6): 98.25%\n",
      "Validation fold accuracy:\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Regression accuracy (within ±5.6): 97.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9766666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regression_accuracy(model, X_test, y_test, tolerance=5.6): #tolerance of 7.5%\n",
    "    \"\"\"\n",
    "    Calculates the percentage of predictions within a tolerance of the true value.\n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        X_test: Test features\n",
    "        y_test: True values\n",
    "        tolerance: Acceptable error (absolute difference)\n",
    "    Returns:\n",
    "        accuracy: Percentage of predictions within tolerance\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    correct = np.abs(y_pred - y_test) <= tolerance\n",
    "    accuracy = np.mean(correct)\n",
    "    print(f\"Regression accuracy (within ±{tolerance}): {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage:\n",
    "print(\"Train fold accuracy:\")\n",
    "regression_accuracy(model_cv, X_train_cv, y_train_cv)\n",
    "print(\"Validation fold accuracy:\")\n",
    "regression_accuracy(model_cv, X_val_cv, y_val_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ef0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (450, 1), Y shape: (450, 4)\n",
      "15/15 [==============================] - 0s 858us/step\n",
      "Classifier accuracy: 97.11%\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "X shape: (450, 1), Y shape: (450, 4)\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Classifier accuracy: 91.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9133333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_classifier_accuracy(clf_model, X, Y):\n",
    "    \"\"\"\n",
    "    Evaluates the classifier model accuracy.\n",
    "    Args:\n",
    "        clf_model: Trained classifier model\n",
    "        X: array-like, regression outputs for test set (shape: [n_samples, 1])\n",
    "        Y: array-like, one-hot encoded true class labels (shape: [n_samples, n_classes])\n",
    "    Returns:\n",
    "        accuracy: float, classification accuracy\n",
    "    \"\"\"\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    # Predict class probabilities\n",
    "    y_pred_probs = clf_model.predict(X)\n",
    "    # Get predicted class indices\n",
    "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "    # Get true class indices\n",
    "    y_true_classes = np.argmax(Y, axis=1)\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "    print(f\"Classifier accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#print(y_test.shape, y_class_test.shape, y_pred.shape)\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "#print(y_test_reshaped.shape)  # Should print (450, 1)\n",
    "evaluate_classifier_accuracy(clf_model_cv, y_test_reshaped, y_class_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_cv = model_cv.predict(X_test)  # shape: (num_samples, 1)\n",
    "evaluate_classifier_accuracy(clf_model_cv, y_pred_cv, y_class_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b5690",
   "metadata": {},
   "source": [
    "96.67, 92 #datqset\n",
    "95.78 91.56 #dataset with new features\n",
    "95.11 90.89 #dataset\n",
    "95.11 92.44 #dataset with new features\n",
    "98.67 91.78 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd9e4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step\n",
      "RMSE (regression model, test set): 2.0916\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Classificação (test set):\n",
      "  Acurácia: 0.9133\n",
      "  Precision: 0.9186\n",
      "  Recall: 0.9133\n",
      "  F1-score: 0.9135\n",
      "Matriz de confusão (test set):\n",
      "[[ 59   7   0   0]\n",
      " [  7 231  19   0]\n",
      " [  0   3 115   0]\n",
      " [  0   0   3   6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# --- RMSE para o modelo de regressão (model_cv) ---\n",
    "y_pred_reg = model_cv.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE (regression model, test set): {rmse:.4f}\")\n",
    "\n",
    "# --- Métricas de classificação para o classificador (clf_model_cv) ---\n",
    "y_pred_probs = clf_model_cv.predict(y_pred_reg.reshape(-1, 1))\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_class_test, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_true_classes, y_pred_classes)\n",
    "precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Classificação (test set):\")\n",
    "print(f\"  Acurácia: {acc:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-score: {f1:.4f}\")\n",
    "\n",
    "print(\"Matriz de confusão (test set):\")\n",
    "print(confusion_matrix(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb79d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
