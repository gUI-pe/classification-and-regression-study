{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f83686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   I     P_sist     P_dist       qPA       Pulse  BreathFreq    Gravity  Class\n",
      "0  1  13.592433  12.220855  8.416754   75.921057   21.635259  40.000000      2\n",
      "1  2  15.775386  13.586879  8.725890   63.813564   19.718734  41.530427      2\n",
      "2  3   3.649369   1.904802  0.000000  197.210213   19.045471  52.730745      3\n",
      "3  4  17.264362  13.700638  8.733333  143.636181   17.621141  34.679911      2\n",
      "4  5  12.705183   9.485389  1.747626   82.636672   12.209535  69.375882      3\n",
      "Temperature Max, Min post normalization: 1.72, -1.23\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "print(df.head())\n",
    "df = df.drop('I', axis=1)\n",
    "\n",
    "# 1. Diferença de Pressões\n",
    "df['P_diff'] = df['P_sist'] - df['P_dist']\n",
    "\n",
    "# 2. Razão de Pressão para Frequência Cardíaca\n",
    "df['Pressure_per_Pulse'] = df['P_sist'] / df['Pulse']\n",
    "\n",
    "# 3. Índice Respiratório\n",
    "df['Resp_Index'] = df['qPA'] / df['BreathFreq']\n",
    "\n",
    "## Removing our target variable\n",
    "\n",
    "selected_features = [\"qPA\", \"Pulse\", \"BreathFreq\" ,\"P_diff\", \"Pressure_per_Pulse\", \"Resp_Index\"]\n",
    "X = df[selected_features].values\n",
    "y_gravity = df[\"Gravity\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(X_scaled[0]):0.2f}, {np.min(X_scaled[0]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff0e572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      P_sist     P_dist       qPA       Pulse  BreathFreq    Gravity  \\\n",
      "0  13.592433  12.220855  8.416754   75.921057   21.635259  40.000000   \n",
      "1  15.775386  13.586879  8.725890   63.813564   19.718734  41.530427   \n",
      "2   3.649369   1.904802  0.000000  197.210213   19.045471  52.730745   \n",
      "3  17.264362  13.700638  8.733333  143.636181   17.621141  34.679911   \n",
      "4  12.705183   9.485389  1.747626   82.636672   12.209535  69.375882   \n",
      "\n",
      "     P_diff  Pressure_per_Pulse  Resp_Index  class_1  class_2  class_3  \\\n",
      "0  1.371578            0.179034    0.389030    False     True    False   \n",
      "1  2.188507            0.247211    0.442518    False     True    False   \n",
      "2  1.744567            0.018505    0.000000    False    False     True   \n",
      "3  3.563724            0.120195    0.495617    False     True    False   \n",
      "4  3.219794            0.153748    0.143136    False    False     True   \n",
      "\n",
      "   class_4  \n",
      "0    False  \n",
      "1    False  \n",
      "2    False  \n",
      "3    False  \n",
      "4    False  \n"
     ]
    }
   ],
   "source": [
    "cat_variables = ['Class']\n",
    "\n",
    "# This will replace the columns with the one-hot encoded ones and keep the columns outside 'columns' argument as it is.\n",
    "df = pd.get_dummies(data = df,\n",
    "                         prefix = \"class\",\n",
    "                         columns = cat_variables)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f04abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 1050\n",
      "test samples: 450\n"
     ]
    }
   ],
   "source": [
    "# Define X (features), y_class e y_gravity\n",
    "y_class = df[[\"class_1\", \"class_2\", \"class_3\", \"class_4\"]].values\n",
    "\n",
    "# Divide em treino e teste\n",
    "X_train, X_test, y_train, y_test, y_class_train, y_class_test = train_test_split(X_scaled, y_gravity, y_class, train_size = 0.7, random_state = RANDOM_STATE)\n",
    "\n",
    "print(f'train samples: {len(X_train)}\\ntest samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d937b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 6) (1050, 4)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_class_train.shape)\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb15ab8",
   "metadata": {},
   "source": [
    "usando K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e0d02d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m\n\u001b[0;32m     11\u001b[0m model_cv \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     12\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(X_train_cv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m     13\u001b[0m     Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m ])\n\u001b[0;32m     18\u001b[0m model_cv\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate on validation fold\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss, mae \u001b[38;5;241m=\u001b[39m model_cv\u001b[38;5;241m.\u001b[39mevaluate(X_val_cv, y_val_cv, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_scaled):\n",
    "    X_train_cv, X_val_cv = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_cv, y_val_cv = y_gravity[train_idx], y_gravity[val_idx]\n",
    "    \n",
    "    # Build a new model for each fold\n",
    "    model_cv = tf.keras.Sequential([\n",
    "        tf.keras.Input(X_train_cv.shape[1]),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model_cv.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    model_cv.fit(X_train_cv, y_train_cv, epochs=600, verbose=0)\n",
    "    \n",
    "    # Evaluate on validation fold\n",
    "    loss, mae = model_cv.evaluate(X_val_cv, y_val_cv, verbose=0)\n",
    "    cv_scores.append(mae)\n",
    "\n",
    "print(f\"Mean MAE across folds: {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1d226",
   "metadata": {},
   "source": [
    "Usando K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c1db601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Fold classifier accuracy: 57.00%\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Fold classifier accuracy: 91.67%\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Fold classifier accuracy: 92.67%\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Fold classifier accuracy: 90.67%\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Fold classifier accuracy: 90.67%\n",
      "Mean classifier accuracy across folds: 84.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "clf_cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_scaled):\n",
    "    X_train_cv, X_val_cv = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_cv, y_val_cv = y_gravity[train_idx], y_gravity[val_idx]\n",
    "    y_class_train_cv, y_class_val_cv = y_class[train_idx], y_class[val_idx]\n",
    "\n",
    "    # 1. Train regression model\n",
    "    model_cv = tf.keras.Sequential([\n",
    "        tf.keras.Input(X_train_cv.shape[1]),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model_cv.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    model_cv.fit(X_train_cv, y_train_cv, epochs=800, verbose=0)\n",
    "\n",
    "    # 2. Predict gravity for train and validation sets\n",
    "    y_train_pred_cv = model_cv.predict(X_train_cv)\n",
    "    y_val_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    # 3. Train classifier on regression predictions (train set)\n",
    "    clf_model_cv = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    clf_model_cv.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    clf_model_cv.fit(y_train_pred_cv, y_class_train_cv, epochs=800, verbose=0)\n",
    "\n",
    "    # 4. Evaluate classifier on validation set\n",
    "    val_acc = clf_model_cv.evaluate(y_val_pred_cv, y_class_val_cv, verbose=0)[1]\n",
    "    print(f\"Fold classifier accuracy: {val_acc*100:.2f}%\")\n",
    "    clf_cv_scores.append(val_acc)\n",
    "\n",
    "print(f\"Mean classifier accuracy across folds: {np.mean(clf_cv_scores)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77bb86ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fold accuracy:\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "Regression accuracy (within ±5.6): 97.25%\n",
      "Validation fold accuracy:\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Regression accuracy (within ±5.6): 95.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regression_accuracy(model, X_test, y_test, tolerance=5.6): #tolerance of 7.5%\n",
    "    \"\"\"\n",
    "    Calculates the percentage of predictions within a tolerance of the true value.\n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        X_test: Test features\n",
    "        y_test: True values\n",
    "        tolerance: Acceptable error (absolute difference)\n",
    "    Returns:\n",
    "        accuracy: Percentage of predictions within tolerance\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    correct = np.abs(y_pred - y_test) <= tolerance\n",
    "    accuracy = np.mean(correct)\n",
    "    print(f\"Regression accuracy (within ±{tolerance}): {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage:\n",
    "print(\"Train fold accuracy:\")\n",
    "regression_accuracy(model_cv, X_train_cv, y_train_cv)\n",
    "print(\"Validation fold accuracy:\")\n",
    "regression_accuracy(model_cv, X_val_cv, y_val_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7ef0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (450, 1), Y shape: (450, 4)\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Classifier accuracy: 98.67%\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "X shape: (450, 1), Y shape: (450, 4)\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Classifier accuracy: 91.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9177777777777778"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_classifier_accuracy(clf_model, X, Y):\n",
    "    \"\"\"\n",
    "    Evaluates the classifier model accuracy.\n",
    "    Args:\n",
    "        clf_model: Trained classifier model\n",
    "        X: array-like, regression outputs for test set (shape: [n_samples, 1])\n",
    "        Y: array-like, one-hot encoded true class labels (shape: [n_samples, n_classes])\n",
    "    Returns:\n",
    "        accuracy: float, classification accuracy\n",
    "    \"\"\"\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    # Predict class probabilities\n",
    "    y_pred_probs = clf_model.predict(X)\n",
    "    # Get predicted class indices\n",
    "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "    # Get true class indices\n",
    "    y_true_classes = np.argmax(Y, axis=1)\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "    print(f\"Classifier accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#print(y_test.shape, y_class_test.shape, y_pred.shape)\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "#print(y_test_reshaped.shape)  # Should print (450, 1)\n",
    "evaluate_classifier_accuracy(clf_model_cv, y_test_reshaped, y_class_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_cv = model_cv.predict(X_test)  # shape: (num_samples, 1)\n",
    "evaluate_classifier_accuracy(clf_model_cv, y_pred_cv, y_class_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b5690",
   "metadata": {},
   "source": [
    "96.67, 92 #datqset\n",
    "95.78 91.56 #dataset with new features\n",
    "95.11 90.89 #dataset\n",
    "95.11 92.44 #dataset with new features\n",
    "98.67 91.78 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
