{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9ca300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1f83686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   I     P_sist     P_dist       qPA       Pulse  BreathFreq    Gravity  Class\n",
      "0  1  13.592433  12.220855  8.416754   75.921057   21.635259  40.000000      2\n",
      "1  2  15.775386  13.586879  8.725890   63.813564   19.718734  41.530427      2\n",
      "2  3   3.649369   1.904802  0.000000  197.210213   19.045471  52.730745      3\n",
      "3  4  17.264362  13.700638  8.733333  143.636181   17.621141  34.679911      2\n",
      "4  5  12.705183   9.485389  1.747626   82.636672   12.209535  69.375882      3\n",
      "Temperature Max, Min post normalization: 1.72, -0.44\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "print(df.head())\n",
    "df = df.drop('I', axis=1)\n",
    "\n",
    "## Removing our target variable\n",
    "\n",
    "selected_features = [\"qPA\", \"Pulse\", \"BreathFreq\"]\n",
    "X = df[selected_features].values\n",
    "y_gravity = df[\"Gravity\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(X_scaled[0]):0.2f}, {np.min(X_scaled[0]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ff0e572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      P_sist     P_dist       qPA       Pulse  BreathFreq    Gravity  class_1  \\\n",
      "0  13.592433  12.220855  8.416754   75.921057   21.635259  40.000000    False   \n",
      "1  15.775386  13.586879  8.725890   63.813564   19.718734  41.530427    False   \n",
      "2   3.649369   1.904802  0.000000  197.210213   19.045471  52.730745    False   \n",
      "3  17.264362  13.700638  8.733333  143.636181   17.621141  34.679911    False   \n",
      "4  12.705183   9.485389  1.747626   82.636672   12.209535  69.375882    False   \n",
      "\n",
      "   class_2  class_3  class_4  \n",
      "0     True    False    False  \n",
      "1     True    False    False  \n",
      "2    False     True    False  \n",
      "3     True    False    False  \n",
      "4    False     True    False  \n"
     ]
    }
   ],
   "source": [
    "cat_variables = ['Class']\n",
    "\n",
    "# This will replace the columns with the one-hot encoded ones and keep the columns outside 'columns' argument as it is.\n",
    "df = pd.get_dummies(data = df,\n",
    "                         prefix = \"class\",\n",
    "                         columns = cat_variables)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "89f04abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 1050\n",
      "test samples: 450\n"
     ]
    }
   ],
   "source": [
    "# Define X (features), y_class e y_gravity\n",
    "y_class = df[[\"class_1\", \"class_2\", \"class_3\", \"class_4\"]].values\n",
    "\n",
    "# Divide em treino e teste\n",
    "X_train, X_test, y_train, y_test, y_class_train, y_class_test = train_test_split(X, y_gravity, y_class, train_size = 0.7, random_state = RANDOM_STATE)\n",
    "\n",
    "print(f'train samples: {len(X_train)}\\ntest samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d937b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 3) (1050, 4)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_class_train.shape)\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "be614369",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(X.shape[1]),\n",
    "    Dense(32, activation='relu', name = 'layer1'),\n",
    "    Dense(16, activation='relu', name = 'layer2'),\n",
    "    Dense(8, activation='relu', name = 'layer3'),\n",
    "    Dense(1, activation='linear', name = 'output')  # Output for regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "447bca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 32)                128       \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 16)                528       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 8)                 136       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc81c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33/33 [==============================] - 1s 8ms/step - loss: 7.3257 - mae: 1.9664\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 4.7822 - mae: 1.6427\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.8550 - mae: 1.6532\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.0349 - mae: 1.6597\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.7735 - mae: 1.5784\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4133 - mae: 1.5377\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.0149 - mae: 1.6430\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.5526 - mae: 1.5905\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.7421 - mae: 1.6254\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.9546 - mae: 1.6623\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.2918 - mae: 1.5197\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.9470 - mae: 1.6695\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8947 - mae: 1.6291\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.0705 - mae: 1.6870\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8316 - mae: 1.7844\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6013 - mae: 1.5629\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.4993 - mae: 1.5696\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8206 - mae: 1.6127\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7321 - mae: 1.6330\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.1113 - mae: 1.6693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5614b5310>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # what metric to monitor (can also use 'val_mae')\n",
    "    patience=10,               # how many epochs to wait before stopping\n",
    "    restore_best_weights=True # keep the best model, not the last one\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,#4400\n",
    "    callbacks=[early_stop],    # here's the EarlyStopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "77bb86ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/33 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step\n",
      "Regression accuracy (within ±5.6): 98.48%\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Regression accuracy (within ±5.6): 93.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9377777777777778"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regression_accuracy(model, X_test, y_test, tolerance=5.6): #tolerance of 7.5%\n",
    "    \"\"\"\n",
    "    Calculates the percentage of predictions within a tolerance of the true value.\n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        X_test: Test features\n",
    "        y_test: True values\n",
    "        tolerance: Acceptable error (absolute difference)\n",
    "    Returns:\n",
    "        accuracy: Percentage of predictions within tolerance\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    correct = np.abs(y_pred - y_test) <= tolerance\n",
    "    accuracy = np.mean(correct)\n",
    "    print(f\"Regression accuracy (within ±{tolerance}): {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage:\n",
    "regression_accuracy(model, X_train, y_train)\n",
    "regression_accuracy(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "07d49ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 8.6419 - mae: 2.0616\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "41c0619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "y_pred shape: (450, 1), y_class_test shape: (450, 4)\n",
      "Epoch 1/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.7914 - accuracy: 0.4971\n",
      "Epoch 2/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1887 - accuracy: 0.5476\n",
      "Epoch 3/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.0612 - accuracy: 0.5476\n",
      "Epoch 4/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.0520 - accuracy: 0.5857\n",
      "Epoch 5/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.0356 - accuracy: 0.5476\n",
      "Epoch 6/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.0261 - accuracy: 0.5819\n",
      "Epoch 7/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.0116 - accuracy: 0.5829\n",
      "Epoch 8/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.6181\n",
      "Epoch 9/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9990 - accuracy: 0.6038\n",
      "Epoch 10/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9839 - accuracy: 0.5962\n",
      "Epoch 11/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9730 - accuracy: 0.6381\n",
      "Epoch 12/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9642 - accuracy: 0.6238\n",
      "Epoch 13/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9551 - accuracy: 0.6000\n",
      "Epoch 14/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.6610\n",
      "Epoch 15/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.6667\n",
      "Epoch 16/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.6648\n",
      "Epoch 17/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.6505\n",
      "Epoch 18/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.6971\n",
      "Epoch 19/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8918 - accuracy: 0.7000\n",
      "Epoch 20/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8757 - accuracy: 0.6800\n",
      "Epoch 21/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8657 - accuracy: 0.6819\n",
      "Epoch 22/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8493 - accuracy: 0.7286\n",
      "Epoch 23/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8363 - accuracy: 0.6924\n",
      "Epoch 24/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8239 - accuracy: 0.7229\n",
      "Epoch 25/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8098 - accuracy: 0.7248\n",
      "Epoch 26/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7971 - accuracy: 0.7419\n",
      "Epoch 27/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7818 - accuracy: 0.7286\n",
      "Epoch 28/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7670 - accuracy: 0.7495\n",
      "Epoch 29/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.7419\n",
      "Epoch 30/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7403 - accuracy: 0.7162\n",
      "Epoch 31/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.7486\n",
      "Epoch 32/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.7400\n",
      "Epoch 33/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.7419\n",
      "Epoch 34/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7552\n",
      "Epoch 35/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.7438\n",
      "Epoch 36/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.7495\n",
      "Epoch 37/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.7590\n",
      "Epoch 38/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6137 - accuracy: 0.8133\n",
      "Epoch 39/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.8248\n",
      "Epoch 40/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.8667\n",
      "Epoch 41/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.8486\n",
      "Epoch 42/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.8686\n",
      "Epoch 43/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8657\n",
      "Epoch 44/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.8724\n",
      "Epoch 45/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.8581\n",
      "Epoch 46/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.8705\n",
      "Epoch 47/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8781\n",
      "Epoch 48/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8752\n",
      "Epoch 49/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8819\n",
      "Epoch 50/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.8943\n",
      "Epoch 51/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.8810\n",
      "Epoch 52/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.8962\n",
      "Epoch 53/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8867\n",
      "Epoch 54/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8886\n",
      "Epoch 55/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8895\n",
      "Epoch 56/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8771\n",
      "Epoch 57/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4084 - accuracy: 0.8981\n",
      "Epoch 58/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.9000\n",
      "Epoch 59/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8857\n",
      "Epoch 60/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.9105\n",
      "Epoch 61/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.9086\n",
      "Epoch 62/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8895\n",
      "Epoch 63/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8933\n",
      "Epoch 64/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8990\n",
      "Epoch 65/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.9029\n",
      "Epoch 66/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.9095\n",
      "Epoch 67/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.9095\n",
      "Epoch 68/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.9019\n",
      "Epoch 69/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.9038\n",
      "Epoch 70/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.9095\n",
      "Epoch 71/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.9105\n",
      "Epoch 72/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.9238\n",
      "Epoch 73/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.9086\n",
      "Epoch 74/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9152\n",
      "Epoch 75/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.9190\n",
      "Epoch 76/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.9181\n",
      "Epoch 77/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.9238\n",
      "Epoch 78/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2891 - accuracy: 0.9010\n",
      "Epoch 79/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.9067\n",
      "Epoch 80/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.9162\n",
      "Epoch 81/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9181\n",
      "Epoch 82/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.9181\n",
      "Epoch 83/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.9124\n",
      "Epoch 84/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.9295\n",
      "Epoch 85/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.9143\n",
      "Epoch 86/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.9267\n",
      "Epoch 87/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9152\n",
      "Epoch 88/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.9200\n",
      "Epoch 89/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9238\n",
      "Epoch 90/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.9210\n",
      "Epoch 91/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9248\n",
      "Epoch 92/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9238\n",
      "Epoch 93/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9333\n",
      "Epoch 94/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9238\n",
      "Epoch 95/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9229\n",
      "Epoch 96/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9257\n",
      "Epoch 97/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9238\n",
      "Epoch 98/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9190\n",
      "Epoch 99/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9286\n",
      "Epoch 100/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.9133\n",
      "Epoch 101/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9238\n",
      "Epoch 102/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9152\n",
      "Epoch 103/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9248\n",
      "Epoch 104/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9248\n",
      "Epoch 105/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9267\n",
      "Epoch 106/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9105\n",
      "Epoch 107/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9229\n",
      "Epoch 108/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9267\n",
      "Epoch 109/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9171\n",
      "Epoch 110/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9257\n",
      "Epoch 111/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9162\n",
      "Epoch 112/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.9238\n",
      "Epoch 113/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9190\n",
      "Epoch 114/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9229\n",
      "Epoch 115/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9219\n",
      "Epoch 116/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9276\n",
      "Epoch 117/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9305\n",
      "Epoch 118/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9286\n",
      "Epoch 119/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9324\n",
      "Epoch 120/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9143\n",
      "Epoch 121/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9190\n",
      "Epoch 122/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9295\n",
      "Epoch 123/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9229\n",
      "Epoch 124/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9276\n",
      "Epoch 125/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9333\n",
      "Epoch 126/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9324\n",
      "Epoch 127/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9305\n",
      "Epoch 128/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9276\n",
      "Epoch 129/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9257\n",
      "Epoch 130/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9295\n",
      "Epoch 131/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9371\n",
      "Epoch 132/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9352\n",
      "Epoch 133/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9410\n",
      "Epoch 134/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9333\n",
      "Epoch 135/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9314\n",
      "Epoch 136/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9257\n",
      "Epoch 137/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9219\n",
      "Epoch 138/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9162\n",
      "Epoch 139/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9333\n",
      "Epoch 140/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9305\n",
      "Epoch 141/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9248\n",
      "Epoch 142/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9314\n",
      "Epoch 143/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9314\n",
      "Epoch 144/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9324\n",
      "Epoch 145/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9419\n",
      "Epoch 146/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9438\n",
      "Epoch 147/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9276\n",
      "Epoch 148/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9371\n",
      "Epoch 149/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9476\n",
      "Epoch 150/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9371\n",
      "Epoch 151/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9419\n",
      "Epoch 152/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9352\n",
      "Epoch 153/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9381\n",
      "Epoch 154/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9571\n",
      "Epoch 155/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9495\n",
      "Epoch 156/450\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.1563 - accuracy: 0.9438\n",
      "Epoch 157/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1557 - accuracy: 0.9362\n",
      "Epoch 158/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9400\n",
      "Epoch 159/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9467\n",
      "Epoch 160/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9438\n",
      "Epoch 161/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9448\n",
      "Epoch 162/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.9438\n",
      "Epoch 163/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9352\n",
      "Epoch 164/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9562\n",
      "Epoch 165/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9429\n",
      "Epoch 166/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9457\n",
      "Epoch 167/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9467\n",
      "Epoch 168/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.9276\n",
      "Epoch 169/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9438\n",
      "Epoch 170/450\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9457\n",
      "Epoch 171/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9457\n",
      "Epoch 172/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9400\n",
      "Epoch 173/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9543\n",
      "Epoch 174/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9533\n",
      "Epoch 175/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1522 - accuracy: 0.9362\n",
      "Epoch 176/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9467\n",
      "Epoch 177/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9524\n",
      "Epoch 178/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9457\n",
      "Epoch 179/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9305\n",
      "Epoch 180/450\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9562\n",
      "Epoch 181/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9448\n",
      "Epoch 182/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9581\n",
      "Epoch 183/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9381\n",
      "Epoch 184/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9467\n",
      "Epoch 185/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9333\n",
      "Epoch 186/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9543\n",
      "Epoch 187/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9552\n",
      "Epoch 188/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9371\n",
      "Epoch 189/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9514\n",
      "Epoch 190/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9476\n",
      "Epoch 191/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9533\n",
      "Epoch 192/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9495\n",
      "Epoch 193/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9610\n",
      "Epoch 194/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9562\n",
      "Epoch 195/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9505\n",
      "Epoch 196/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9581\n",
      "Epoch 197/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9476\n",
      "Epoch 198/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9571\n",
      "Epoch 199/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9552\n",
      "Epoch 200/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9543\n",
      "Epoch 201/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9448\n",
      "Epoch 202/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9533\n",
      "Epoch 203/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9390\n",
      "Epoch 204/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9495\n",
      "Epoch 205/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9543\n",
      "Epoch 206/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9610\n",
      "Epoch 207/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9543\n",
      "Epoch 208/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9467\n",
      "Epoch 209/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9600\n",
      "Epoch 210/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9524\n",
      "Epoch 211/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9505\n",
      "Epoch 212/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9543\n",
      "Epoch 213/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9514\n",
      "Epoch 214/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9514\n",
      "Epoch 215/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9381\n",
      "Epoch 216/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9648\n",
      "Epoch 217/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9448\n",
      "Epoch 218/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9648\n",
      "Epoch 219/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9543\n",
      "Epoch 220/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9514\n",
      "Epoch 221/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9486\n",
      "Epoch 222/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9514\n",
      "Epoch 223/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9600\n",
      "Epoch 224/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9543\n",
      "Epoch 225/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9533\n",
      "Epoch 226/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9581\n",
      "Epoch 227/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9562\n",
      "Epoch 228/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9505\n",
      "Epoch 229/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9486\n",
      "Epoch 230/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9638\n",
      "Epoch 231/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9629\n",
      "Epoch 232/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9505\n",
      "Epoch 233/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9533\n",
      "Epoch 234/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9543\n",
      "Epoch 235/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9600\n",
      "Epoch 236/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9514\n",
      "Epoch 237/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9314\n",
      "Epoch 238/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9562\n",
      "Epoch 239/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9657\n",
      "Epoch 240/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9438\n",
      "Epoch 241/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9676\n",
      "Epoch 242/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9610\n",
      "Epoch 243/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9562\n",
      "Epoch 244/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9581\n",
      "Epoch 245/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9524\n",
      "Epoch 246/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9610\n",
      "Epoch 247/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9571\n",
      "Epoch 248/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9552\n",
      "Epoch 249/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9629\n",
      "Epoch 250/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9629\n",
      "Epoch 251/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9667\n",
      "Epoch 252/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9533\n",
      "Epoch 253/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9638\n",
      "Epoch 254/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9590\n",
      "Epoch 255/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9629\n",
      "Epoch 256/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9390\n",
      "Epoch 257/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9371\n",
      "Epoch 258/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9476\n",
      "Epoch 259/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9476\n",
      "Epoch 260/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9657\n",
      "Epoch 261/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9514\n",
      "Epoch 262/450\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.9610\n",
      "Epoch 263/450\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9600\n",
      "Epoch 264/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9600\n",
      "Epoch 265/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9390\n",
      "Epoch 266/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9448\n",
      "Epoch 267/450\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.9590\n",
      "Epoch 268/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9676\n",
      "Epoch 269/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9638\n",
      "Epoch 270/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9533\n",
      "Epoch 271/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9505\n",
      "Epoch 272/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9543\n",
      "Epoch 273/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9686\n",
      "Epoch 274/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9695\n",
      "Epoch 275/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9695\n",
      "Epoch 276/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9495\n",
      "Epoch 277/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9610\n",
      "Epoch 278/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9571\n",
      "Epoch 279/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9667\n",
      "Epoch 280/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9705\n",
      "Epoch 281/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9619\n",
      "Epoch 282/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9733\n",
      "Epoch 283/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9524\n",
      "Epoch 284/450\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.1299 - accuracy: 0.9410\n",
      "Epoch 285/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9648\n",
      "Epoch 286/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9571\n",
      "Epoch 287/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9619\n",
      "Epoch 288/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9505\n",
      "Epoch 289/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9686\n",
      "Epoch 290/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9600\n",
      "Epoch 291/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9619\n",
      "Epoch 292/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9714\n",
      "Epoch 293/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9705\n",
      "Epoch 294/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9533\n",
      "Epoch 295/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9657\n",
      "Epoch 296/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9705\n",
      "Epoch 297/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9610\n",
      "Epoch 298/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9552\n",
      "Epoch 299/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9524\n",
      "Epoch 300/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9457\n",
      "Epoch 301/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9638\n",
      "Epoch 302/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9581\n",
      "Epoch 303/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9648\n",
      "Epoch 304/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9724\n",
      "Epoch 305/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9600\n",
      "Epoch 306/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9714\n",
      "Epoch 307/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9600\n",
      "Epoch 308/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9581\n",
      "Epoch 309/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9619\n",
      "Epoch 310/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9752\n",
      "Epoch 311/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9610\n",
      "Epoch 312/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9676\n",
      "Epoch 313/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9505\n",
      "Epoch 314/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9733\n",
      "Epoch 315/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9743\n",
      "Epoch 316/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9648\n",
      "Epoch 317/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9648\n",
      "Epoch 318/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9695\n",
      "Epoch 319/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9619\n",
      "Epoch 320/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9533\n",
      "Epoch 321/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9743\n",
      "Epoch 322/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9714\n",
      "Epoch 323/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9724\n",
      "Epoch 324/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9600\n",
      "Epoch 325/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9810\n",
      "Epoch 326/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9610\n",
      "Epoch 327/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9752\n",
      "Epoch 328/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9762\n",
      "Epoch 329/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9695\n",
      "Epoch 330/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9705\n",
      "Epoch 331/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9733\n",
      "Epoch 332/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9781\n",
      "Epoch 333/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9581\n",
      "Epoch 334/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9676\n",
      "Epoch 335/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9657\n",
      "Epoch 336/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9619\n",
      "Epoch 337/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9705\n",
      "Epoch 338/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9562\n",
      "Epoch 339/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9724\n",
      "Epoch 340/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9619\n",
      "Epoch 341/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9676\n",
      "Epoch 342/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9695\n",
      "Epoch 343/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9648\n",
      "Epoch 344/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9648\n",
      "Epoch 345/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9771\n",
      "Epoch 346/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9629\n",
      "Epoch 347/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9514\n",
      "Epoch 348/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9638\n",
      "Epoch 349/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9724\n",
      "Epoch 350/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9533\n",
      "Epoch 351/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9619\n",
      "Epoch 352/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9667\n",
      "Epoch 353/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9705\n",
      "Epoch 354/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9857\n",
      "Epoch 355/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9638\n",
      "Epoch 356/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9648\n",
      "Epoch 357/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9686\n",
      "Epoch 358/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9629\n",
      "Epoch 359/450\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9695\n",
      "Epoch 360/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9762\n",
      "Epoch 361/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9524\n",
      "Epoch 362/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9752\n",
      "Epoch 363/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9686\n",
      "Epoch 364/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9619\n",
      "Epoch 365/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9657\n",
      "Epoch 366/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9733\n",
      "Epoch 367/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9638\n",
      "Epoch 368/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9695\n",
      "Epoch 369/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9571\n",
      "Epoch 370/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9781\n",
      "Epoch 371/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9657\n",
      "Epoch 372/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9724\n",
      "Epoch 373/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9667\n",
      "Epoch 374/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9476\n",
      "Epoch 375/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9733\n",
      "Epoch 376/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9676\n",
      "Epoch 377/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9695\n",
      "Epoch 378/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9619\n",
      "Epoch 379/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9781\n",
      "Epoch 380/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.9667\n",
      "Epoch 381/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9752\n",
      "Epoch 382/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9629\n",
      "Epoch 383/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9743\n",
      "Epoch 384/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9724\n",
      "Epoch 385/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9714\n",
      "Epoch 386/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9714\n",
      "Epoch 387/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9705\n",
      "Epoch 388/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9571\n",
      "Epoch 389/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9790\n",
      "Epoch 390/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9724\n",
      "Epoch 391/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9714\n",
      "Epoch 392/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9705\n",
      "Epoch 393/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9667\n",
      "Epoch 394/450\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9676\n",
      "Epoch 395/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9752\n",
      "Epoch 396/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9610\n",
      "Epoch 397/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9733\n",
      "Epoch 398/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9733\n",
      "Epoch 399/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9724\n",
      "Epoch 400/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9638\n",
      "Epoch 401/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9514\n",
      "Epoch 402/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9686\n",
      "Epoch 403/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9714\n",
      "Epoch 404/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9638\n",
      "Epoch 405/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9695\n",
      "Epoch 406/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9762\n",
      "Epoch 407/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9714\n",
      "Epoch 408/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9686\n",
      "Epoch 409/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9629\n",
      "Epoch 410/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9619\n",
      "Epoch 411/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9695\n",
      "Epoch 412/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9743\n",
      "Epoch 413/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9743\n",
      "Epoch 414/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9762\n",
      "Epoch 415/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9705\n",
      "Epoch 416/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9771\n",
      "Epoch 417/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9676\n",
      "Epoch 418/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9733\n",
      "Epoch 419/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9714\n",
      "Epoch 420/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9676\n",
      "Epoch 421/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9781\n",
      "Epoch 422/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9657\n",
      "Epoch 423/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9724\n",
      "Epoch 424/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9781\n",
      "Epoch 425/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9695\n",
      "Epoch 426/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9762\n",
      "Epoch 427/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9838\n",
      "Epoch 428/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9724\n",
      "Epoch 429/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9762\n",
      "Epoch 430/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9724\n",
      "Epoch 431/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9695\n",
      "Epoch 432/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9705\n",
      "Epoch 433/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9771\n",
      "Epoch 434/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9686\n",
      "Epoch 435/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9657\n",
      "Epoch 436/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9733\n",
      "Epoch 437/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9629\n",
      "Epoch 438/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9276\n",
      "Epoch 439/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9714\n",
      "Epoch 440/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9629\n",
      "Epoch 441/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9762\n",
      "Epoch 442/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9819\n",
      "Epoch 443/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9829\n",
      "Epoch 444/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9752\n",
      "Epoch 445/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9600\n",
      "Epoch 446/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9600\n",
      "Epoch 447/450\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9810\n",
      "Epoch 448/450\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9667\n",
      "Epoch 449/450\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9676\n",
      "Epoch 450/450\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e56c39fdc0>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)  # shape: (num_samples, 1)\n",
    "\n",
    "# Build the classifier\n",
    "clf_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),  # Input is y_pred from regression\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "clf_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "print(f\"y_pred shape: {y_pred.shape}, y_class_test shape: {y_class_test.shape}\")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # what metric to monitor (can also use 'val_accuracy')\n",
    "    patience=10,               # how many epochs to wait before stopping\n",
    "    restore_best_weights=True  # keep the best model, not the last one\n",
    ")\n",
    "clf_model.fit(\n",
    "    y_train, y_class_train,\n",
    "    epochs=450,\n",
    "    callbacks=[early_stop],    # here's the EarlyStopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "8a717ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n",
      "Predicted classes: [0 0 1 1 1 1 2 2 1 1 1 2 1 1 0 2 1 2 0 1 0 1 1 0 2 1 0 1 2 0 1 1 1 1 1 2 1\n",
      " 1 1 1 1 2 0 1 2 0 1 1 0 1 2 1 1 0 1 0 0 1 1 2 0 0 1 1 1 2 1 1 2 1 1 1 1 1\n",
      " 1 1 2 0 0 1 1 2 2 2 2 2 1 0 2 1 1 2 1 1 1 1 2 1 1 1 2 1 1 2 0 1 2 2 1 1 1\n",
      " 1 0 1 1 1 2 1 0 0 1 1 1 0 1 2 1 2 0 1 1 2 1 1 0 2 1 1 0 0 1 1 1 2 1 2 1 0\n",
      " 1 2 1 2 2 1 0 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 0 0 1 1 1 0 1 2 0 0 1 1 1 1\n",
      " 0 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 2 0 1 1 0 0 2 2 1 2 2 1 1 1 2 1 2 0 1 2 2\n",
      " 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 0 1 1 2 1 1 0 1 1 1 1 2 2 2 1 1 0 1 1\n",
      " 1 1 1 1 2 1 0 2 1 2 2 1 0 1 1 1 2 1 0 1 1 1 1 2 2 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 2 1 1 2 2 1 1 1 1 2 1 1 2 0 2 2 1 1 1 2 1 1 1 1 1 2 1 2 2 0 1 1 2 0 1 0\n",
      " 1 1 2 1 1 1 2 2 2 1 2 1 0 0 2 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 1 1 1 1 0 0 1\n",
      " 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 2 2 1 2 1 0 2 0 1 1 1 1 2 1 1 2 2 1 0 1 2 1\n",
      " 1 2 0 1 0 2 0 1 2 1 2 2 1 0 0 0 2 1 0 2 2 1 0 1 0 2 0 1 1 1 1 1 2 0 1 1 1\n",
      " 0 2 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "y_class_pred = np.argmax(clf_model.predict(y_pred), axis=1)\n",
    "print(\"Predicted classes:\", y_class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "85b95555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True classes: [0 0 1 1 1 1 2 2 1 1 1 3 1 1 0 2 1 2 0 1 0 1 1 0 2 1 0 1 2 1 1 1 1 1 2 2 1\n",
      " 1 1 1 1 3 1 1 2 0 1 1 1 1 2 1 1 0 1 0 0 2 1 1 0 0 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 2 1 2 0 0 1 1 2 2 2 2 2 1 0 2 1 1 2 1 1 1 1 2 1 1 1 2 0 1 2 0 1 2 2 1 2 1\n",
      " 1 0 1 1 1 1 1 0 0 0 1 0 0 1 2 1 3 0 1 1 2 1 1 0 2 1 2 0 0 1 1 1 2 2 2 2 0\n",
      " 1 2 1 2 2 1 0 2 1 2 1 1 1 2 2 1 1 2 1 2 1 2 1 0 1 1 1 1 1 1 2 0 0 1 1 1 1\n",
      " 0 1 2 0 1 0 1 3 1 2 2 1 1 2 0 1 2 0 1 1 0 1 3 2 1 2 3 1 1 1 2 1 2 0 1 1 2\n",
      " 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 0 1 1 2 1 1 0 1 1 1 1 2 2 2 1 1 0 1 2\n",
      " 1 2 1 1 2 1 0 2 1 2 2 1 1 1 1 1 2 1 0 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 2 1 1 1 2 1 1 1 1 2 1 1 2 0 2 2 1 1 1 2 1 1 1 0 1 3 1 2 2 0 1 1 2 0 1 0\n",
      " 1 1 2 1 1 1 2 2 2 1 2 1 0 1 2 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 1 1 2 1 0 0 1\n",
      " 1 1 1 2 1 1 3 1 1 1 1 1 2 1 2 2 3 1 2 1 0 2 0 1 1 1 1 1 1 1 2 1 1 1 1 2 1\n",
      " 1 1 0 1 0 1 0 1 2 1 2 2 1 1 0 0 2 1 1 2 2 2 0 1 0 2 0 1 1 1 1 1 2 0 1 1 1\n",
      " 0 2 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"True classes:\", np.argmax(y_class_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "e7ef0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n",
      "X shape: (450, 1), Y shape: (450, 4)\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Classifier accuracy: 91.33%\n",
      "X shape: (450, 1), Y shape: (450, 4)\n",
      "15/15 [==============================] - 0s 897us/step\n",
      "Classifier accuracy: 96.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_classifier_accuracy(clf_model, X, Y):\n",
    "    \"\"\"\n",
    "    Evaluates the classifier model accuracy.\n",
    "    Args:\n",
    "        clf_model: Trained classifier model\n",
    "        X: array-like, regression outputs for test set (shape: [n_samples, 1])\n",
    "        Y: array-like, one-hot encoded true class labels (shape: [n_samples, n_classes])\n",
    "    Returns:\n",
    "        accuracy: float, classification accuracy\n",
    "    \"\"\"\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    # Predict class probabilities\n",
    "    y_pred_probs = clf_model.predict(X)\n",
    "    # Get predicted class indices\n",
    "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "    # Get true class indices\n",
    "    y_true_classes = np.argmax(Y, axis=1)\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "    print(f\"Classifier accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "y_pred = model.predict(X_test)  # shape: (num_samples, 1)\n",
    "\n",
    "# Example usage:\n",
    "evaluate_classifier_accuracy(clf_model, y_pred, y_class_test)\n",
    "\n",
    "#print(y_test.shape, y_class_test.shape, y_pred.shape)\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "#print(y_test_reshaped.shape)  # Should print (450, 1)\n",
    "evaluate_classifier_accuracy(clf_model, y_test_reshaped, y_class_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d68f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
